cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(aes(colour="red")) +
geom_line(aes(x, y, linetype = cutoff), cutoff)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(aes(colour="red")) +
geom_line(aes(x, y, linetype = cutoff), cutoff) + opts(legend.position = "none")
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + opts(legend.position = "none")
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + opts(legend.position = "none")
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + opts(legend.position = "none")
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + guides(color=FALSE)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + guides(colour=FALSE)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff) + guides(fill=FALSE)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
?geom_line
library(broom)
df <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
ggplot(df, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE)
#x <- mtcars$wt
#   res1 <- resid(fit1)
#    e <- res1
#    n <- length(e)
#    plot(x, e,
#         main="mpg~wt+qsec+am",
#         xlab="wt",
#         ylab="Residuals",
#         bg="lightblue",
#         col="black", cex = 2, pch = 21,frame = FALSE)
#    abline(h = 0, lwd = 2)
#    for (i in 1 : n)
#        lines(c(x[i], x[i]), c(e[i], 0), col = "red" , lwd = 2)
library(broom)
library(gridExtra)
df1 <- augment(fit2)
df2 <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
resid1 <- ggplot(df1, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE)
resid2 <- ggplot(df2, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE)
grid.arrange(resid1, resid2, ncol=2)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
# Load the data and examine its structure:
data(mtcars)
str(mtcars)
transmission_t_test <- t.test(mtcars[mtcars$am==1,1], mtcars[mtcars$am==0,1],
alternative="two.sided", paired=FALSE)
fit1 <- lm(data=mtcars, mpg~wt+cyl+disp)
summary(fit1)$coefficient
fit2 <- lm(mpg ~ am, data=mtcars)
fit3 <- lm(mpg ~ ., data=mtcars)
fit4 <- lm(mpg ~ wt, data=mtcars)
anova(fit2, fit1, fit3, fit4)
library(broom)
library(gridExtra)
df1 <- augment(fit2)
df2 <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
resid1 <- ggplot(df1, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE)
resid2 <- ggplot(df2, aes(x = .fitted, y = .resid)) + geom_point(color="red3") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE)
grid.arrange(resid1, resid2, ncol=2)
library(broom)
library(gridExtra)
df1 <- augment(fit2)
df2 <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
resid1 <- ggplot(df1, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: Transmission Type vs. MPG")
resid2 <- ggplot(df2, aes(x = .fitted, y = .resid)) + geom_point(color="red3") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: wt+cyl+disp vs. MPG")
grid.arrange(resid1, resid2, ncol=2)
library(broom)
library(gridExtra)
df1 <- augment(fit2)
df2 <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
resid1 <- ggplot(df1, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: am ~ mpg")
resid2 <- ggplot(df2, aes(x = .fitted, y = .resid)) + geom_point(color="red3") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: wt+cyl+disp ~mpg")
grid.arrange(resid1, resid2, ncol=2)
summary(fit1)
summ <- summary(fit1)
summary(fit2)$r.squared
install.packages("pander")
transmission_t_test$statistic
structure(mtcars)
summary(mtcars)
dimensions(mtcars)
dim(mtcars)
head(mtcars)
head(mtcars,3)
fit2 <- lm(mpg ~ am, data=mtcars)
fit3 <- lm(mpg ~ ., data=mtcars)
fit4 <- lm(mpg ~ wt, data=mtcars)
fit_anova <- anova(fit2, fit1, fit3, fit4)
fit_anova$`Pr(>F)`
fit_anova$`Pr(>F)`[2]
pander(fit_anova$`Pr(>F)`[2])
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(pander)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
pander(fit_anova$`Pr(>F)`[2])
?grid.arrance
?grid.arrange
library(broom)
library(gridExtra)
df1 <- augment(fit2)
df2 <- augment(fit1)
cutoff <- data.frame( x = c(-Inf, Inf), y = 0, cutoff = factor(0) )
resid1 <- ggplot(df1, aes(x = .fitted, y = .resid)) + geom_point(color="blue") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: mpg ~ am")
resid2 <- ggplot(df2, aes(x = .fitted, y = .resid)) + geom_point(color="red3") +
geom_line(aes(x, y, linetype = cutoff), cutoff, show.legend = FALSE) +
ggtitle("Residuals: mpg ~ wt+cyl+disp+am")
grid.arrange(resid1, resid2, nrow=2)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
?createDataPartition
??createDataPartition
load(caret)
install.packages("caret")
load(Caret)
load(caret)
library(caret)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
rm(training)
rm(testing)
rm(trainIndex)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
rm(test)
rm(train)
rm(add.scope())
rm(adData)
rm(predictors)
rm(testing)
rm(trainIndex)
rm(training)
rm(diagnosis)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
install.packages("gbm")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
install.packages("randomForest")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
install.packages("e1071")
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
rm(adData)
rm(predDF)
rm(predictors)
rm(testing)
rm(training)
rm(combModFit)
rm(combPred)
rm(diagnosis)
rm(mod_gbm)
rm(mod_rf)
rm(mod)
rm(mod_lda)
rm(pred_rf
)
rm(pred_gbm)
rm(pred_lda
)
rm(inTrain)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
# fit a Random Forest model
alz.fit.rf = train(diagnosis ~ .,
data = training,
method = "rf")
set.seed(62433)
# fit a Gradient Boosting Machine model
alz.fit.gbm = train(diagnosis ~ .,
data = training,
method = "gbm", verbose = FALSE)
set.seed(62433)
# fit a Linear Discriminant Analysis model
alz.fit.lda = train(diagnosis ~ .,
data = training,
method = "lda")
postResample(predict(alz.fit.rf, testing), testing$diagnosis)
postResample(predict(alz.fit.gbm, testing), testing$diagnosis
)
postResample(predict(alz.fit.lda, testing), testing$diagnosis)
predDF = data.frame(
predict(alz.fit.rf, testing),
predict(alz.fit.gbm, testing),
predict(alz.fit.lda, testing),
diagnosis = testing$diagnosi
s)
predDF = data.frame(
predict(alz.fit.rf, testing),
predict(alz.fit.gbm, testing),
predict(alz.fit.lda, testing),
diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data=predDF)
combPred <- predict(combModFit, predDF)
# resolve overall agreement rate and Kappa
postResample(combPred, testing$diagnosis)
install.packages("rattle")
install.packages("repmis")
library(caret); library(rattle); library(rpart); library(rpart.plot)
library(randomForest); library(repmis)
install.packages("corrplot")
install.packages("rpart.plot")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
train_url <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_file <- "./data/pml-training.csv"
test_file  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(train_file)) {
download.file(train_url, destfile=train_file, method="curl")
}
if (!file.exists(test_file)) {
download.file(test_url, destfile=test_file, method="curl")
}
getwd()
setwd("datascience/PracticalMachineLearning/")
train_url <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_file <- "./data/pml-training.csv"
test_file  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(train_file)) {
download.file(train_url, destfile=train_file, method="curl")
}
if (!file.exists(test_file)) {
download.file(test_url, destfile=test_file, method="curl")
}
train_raw <- read.csv("./data/pml-training.csv")
test_raw <- read.csv("./data/pml-testing.csv")
dim(train_raw)
dim(test_raw)
sum(complete.cases(train_raw))
train_raw <- train_raw[, colSums(is.na(train_raw)) == 0]
test_raw <- test_raw[, colSums(is.na(test_raw)) == 0]
classe <- train_raw$classe
train_to_remove <- grepl("^X|timestamp|window", names(train_raw))
train_raw <- train_raw[, !train_to_remove]
train_clean <- train_raw[, sapply(train_raw, is.numeric)]
train_clean$classe <- classe
test_to_remove <- grepl("^X|timestamp|window", names(test_raw))
test_raw <- test_raw[, !test_to_remove]
test_clean <- test_raw[, sapply(test_raw, is.numeric)]
set.seed(22519) # For reproducibility
in_train <- createDataPartition(train_clean$classe, p=0.70, list=F)
train_data <- train_clean[in_train, ]
val_data <- train_clean[-in_train, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=train_data, method="rf", trControl=controlRf, ntree=250)
modelRf
predictRf <- predict(modelRf, val_data)
confusionMatrix(val_data$classe, predictRf)
accuracy <- postResample(predictRf, val_data$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(val_data$classe, predictRf)$overall[1])
oose
result <- predict(modelRf, test_clean[, -length(names(test_clean))])
result
corrPlot <- cor(train_data[, -length(names(train_data))])
corrplot(corrPlot, method="color")
treeModel <- rpart(classe ~ ., data=train_data, method="class")
fancyRpartPlot(modelRf$finalModel)
prp(treeModel) # fast plot
fancyRpartPlot(treeModel)
dev.new(width=12,height=10)
fancyRpartPlot(treeModel)
dev.new(width=16,height=10)
fancyRpartPlot(treeModel)
fit_rpart <- train(classe ~ ., data = train_data, method = "rpart",  trControl = controlRf)
fancyRpartPlot(fit_rpart$finalModel)
str(fit_rpart$finalModel)
str(fit_r)
str(fit_rpart)
summary(fit_rpart)
?fancyRpartPlot
predictRf <- predict(modelRf, val_data)
confusionMatrix(val_data$classe, predictRf)
accuracy <- postResample(predictRf, val_data$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(val_data$classe, predictRf)$overall[1])
oose
